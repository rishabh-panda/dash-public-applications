{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_ID  Customer_ID  Total_Purchases  Amount  Total_Amount  \\\n",
      "0         4340470        10000                5  299.74       1498.69   \n",
      "1         8180050        10000                7   61.42        429.92   \n",
      "2         4759669        10000                6  447.18       2683.06   \n",
      "3         8901617        10000                3  131.97        395.90   \n",
      "4         6592641        10001                3  122.49        367.46   \n",
      "\n",
      "  Product_Category Product_Type            Products   Feedback  Ratings  \n",
      "0         Clothing       Shorts        Khaki shorts       Good        3  \n",
      "1          Grocery        Water     Sparkling water  Excellent        5  \n",
      "2      Electronics       Tablet  Amazon Fire Tablet    Average        2  \n",
      "3       Home Decor      Bedding               Quilt       Good        4  \n",
      "4          Grocery   Soft Drink          Grape soda        Bad        1  \n",
      "\n",
      "Data loaded successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Data Extraction and Loading\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import urllib3\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Suppress only the single InsecureRequestWarning from urllib3 needed\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Set Kaggle API credentials (ensure kaggle.json is in ~/.kaggle or %USERPROFILE%\\.kaggle\\)\n",
    "kaggle_json_path = os.path.join(os.getenv('USERPROFILE'), '.kaggle', 'kaggle.json')\n",
    "\n",
    "# Load Kaggle API credentials from the kaggle.json file\n",
    "with open(kaggle_json_path, 'r') as file:\n",
    "    kaggle_credentials = json.load(file)\n",
    "    kaggle_username = kaggle_credentials['username']\n",
    "    kaggle_key = kaggle_credentials['key']\n",
    "\n",
    "# Kaggle API endpoint and headers\n",
    "dataset_url = 'https://www.kaggle.com/api/v1/datasets/download/dinachanthan/cleaned-retail-shop-dataset'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0',\n",
    "    'Authorization': f'Bearer {kaggle_key}'\n",
    "}\n",
    "\n",
    "# Create the data directory if it doesn't exist\n",
    "data_dir = './data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Download the dataset with SSL verification disabled\n",
    "response = requests.get(dataset_url, headers=headers, stream=True, verify=False)\n",
    "\n",
    "# Use a temporary in-memory buffer to handle the zip file\n",
    "zip_buffer = BytesIO()\n",
    "\n",
    "total_size = int(response.headers.get('content-length', 0))\n",
    "chunk_size = total_size // 4\n",
    "\n",
    "if response.status_code == 200:\n",
    "    for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "        zip_buffer.write(chunk)\n",
    "\n",
    "    # Verify if the file is a valid zip file\n",
    "    zip_buffer.seek(0)\n",
    "    if zipfile.is_zipfile(zip_buffer):\n",
    "        # Extract the dataset using ThreadPoolExecutor for parallel processing\n",
    "        with ZipFile(zip_buffer, 'r') as zip_ref:\n",
    "            def extract_file(file):\n",
    "                zip_ref.extract(file, data_dir)\n",
    "\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                executor.map(extract_file, zip_ref.namelist())\n",
    "\n",
    "        # Find the CSV file in the extracted files\n",
    "        extracted_files = os.listdir(data_dir)\n",
    "        csv_files = [file for file in extracted_files if file.endswith('.csv')]\n",
    "\n",
    "        if not csv_files:\n",
    "            raise FileNotFoundError(\"No CSV file found in the extracted dataset.\")\n",
    "        \n",
    "        data_path = os.path.join(data_dir, csv_files[0])\n",
    "\n",
    "        # Load a sample of the dataset to infer data types\n",
    "        total_rows = sum(1 for _ in open(data_path)) - 1  # Subtract 1 for the header\n",
    "        ten_percent_rows = int(total_rows * 0.10)\n",
    "        sample_df = pd.read_csv(data_path, nrows=ten_percent_rows)\n",
    "        dtype_spec = sample_df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "\n",
    "        # Optimize data types for pandas\n",
    "        for column, dtype in dtype_spec.items():\n",
    "            if dtype.startswith('int'):\n",
    "                dtype_spec[column] = 'Int64'  # Use pandas nullable integer type\n",
    "            elif dtype.startswith('float'):\n",
    "                dtype_spec[column] = 'float64'\n",
    "            elif dtype == 'object':\n",
    "                dtype_spec[column] = 'category'\n",
    "\n",
    "        # Use 'pyarrow' for faster CSV reading if available, fallback to default 'c' engine\n",
    "        try:\n",
    "            df = pd.read_csv(data_path, engine='pyarrow', dtype=dtype_spec)\n",
    "        except ImportError:\n",
    "            df = pd.read_csv(data_path, engine='c', dtype=dtype_spec)\n",
    "\n",
    "        # Display the first few rows of the dataframe\n",
    "        print(df.head())\n",
    "        print('\\nData loaded successfully.\\n')\n",
    "    else:\n",
    "        print(\"The downloaded file is not a valid zip file.\")\n",
    "else:\n",
    "    print(f\"Failed to download the dataset. Status code: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
